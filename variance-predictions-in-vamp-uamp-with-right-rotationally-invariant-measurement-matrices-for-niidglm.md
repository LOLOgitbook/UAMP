# Variance Predictions in VAMP/UAMP with Right Rotationally Invariant Measurement Matrices for niidGLM



## lemma 1

这段描述是关于一种数学定理（Lemma 1），用于处理特定类型的矩阵和它们的性质。这个定理主要关注在大规模随机矩阵的背景下，矩阵函数的平均行为。&#x20;

定理的主要内容是：

给定条件：

* (P) 是一个有界谱范数的厄米矩阵。这意味着(P)的所有特征值的绝对值都不会超过某个固定的实数上限。
* (V \in \mathbb{R}^{N \times M}) 是一个从Haar分布（一种在单位圆上均匀分布的随机矩阵分布）中选取的M列的子矩阵，这里M小于N。
* (B) 是一个非负定的矩阵，其谱范数（即最大特征值的绝对值）有一个上限。
* (D) 是一个只包含正项的对角矩阵。

定理表述： 当你构造一个由这些矩阵(V, P, B, D)构成的特定矩阵函数，并计算它的平均行踪（迹），那么这个平均行踪会趋近于一个简化形式的行踪的值。具体来说，就是 \[ \frac{1}{N} \text{tr} \left\[ B\left(VPV^T + D\right)^{-1} \right] - \frac{1}{N} \text{tr} \left\[ B(eI + D)^{-1} \right] \rightarrow 0 ] 几乎肯定地趋于0。这意味着这两个行踪的值在大N的极限下是相等的。

这里的标量(e)是通过以下方程组得到的唯一解（固定点）： \[ e = \frac{1}{N} \text{tr} \left\[ P \left(eP + (1 - e)eI\right)^{-1} \right], \quad e = \frac{1}{N} \text{tr} \left\[ B(eI + D)^{-1} \right] ]

简而言之，这个定理告诉我们，在处理具有特定分布（如Haar分布）的随机矩阵时，某些复杂矩阵表达式的平均行为可以通过一个更简单的表达式来近似。这个结果在理论和实际应用中非常有用，因为它为分析和计算提供了便利，尤其是在处理大规模数据或复杂系统时。

## (10) MMSE solution 推导

最小均方误差（MMSE）估计的推导是一个经典问题，通常在信号处理和统计估计的背景下进行。推导的核心思想是找到一个估计值，这个估计值能够最小化真实信号和估计信号之间差的平方的期望值，即均方误差（MSE）。以下是一个简化的推导过程：

#### 问题设置

考虑线性观测模型：

\[y = Ax + v]

其中：

* (y) 是 (N \times 1) 的观测向量。
* (A) 是 (N \times M) 的已知矩阵。
* (x) 是 (M \times 1) 的未知向量，我们希望估计。
* (v) 是 (N \times 1) 的噪声向量，假设为高斯白噪声，均值为0，方差为 (\sigma^2\_v I)。

我们希望找到 (x) 的估计 (\hat{x})，使得MSE最小化：

\[MSE = E\left\[|\hat{x} - x|^2\right]]

#### 推导步骤

1. **构建损失函数**：定义损失函数为均方误差 (J(\hat{x}) = E\left\[|\hat{x} - x|^2\right])。
2.  **应用向量微积分**：对于每个元素 (\hat{x}\_i)，计算损失函数的导数并令其等于0以求得极小值。对于整个向量 (\hat{x})，这可以表示为：

    \[\frac{\partial J}{\partial \hat{x\}} = 0]

    具体来说：

    \[J(\hat{x}) = E\left\[(\hat{x} - x)^T(\hat{x} - x)\right]]

    展开并使用 (y = Ax + v)，我们得到：

    \[J(\hat{x}) = E\left\[(\hat{x} - Ax - v)^T(\hat{x} - Ax - v)\right]]

    对 (\hat{x}) 求导并设为0，找到最小化MSE的 (\hat{x}) 表达式。
3.  **求解 (\hat{x})**：最终得到 (\hat{x}) 的表达式为：

    \[\hat{x} = \left(A^TA + \frac{\sigma^2\_v}{\sigma^2\_x}I\right)^{-1}A^Ty]

    其中 (\sigma^2\_x) 代表 (x) 的先验方差，如果不知道 (x) 的先验方差，可以忽略与 (\sigma^2\_x) 相关的项，即 (\frac{\sigma^2\_v}{\sigma^2\_x}I)。

#### 结论

这个过程展示了如何通过最小化观测值和估计值之间的均方误差来得到MMSE估计。注意，这里的推导简化了一些步骤，实际应用中可能需要考虑更多细节，比如 (x) 的先验分布等。在高斯噪声的假设下，这个推导是有效的，但在其他类型的噪声或分布假设下，推导过程可能需要调整。

协方差矩阵 (C\_{\text{MMSE\}}) 在最小均方误差（MMSE）估计的背景下，代表了估计值 (\hat{x}) 的误差的协方差。这个矩阵提供了关于估计精度和估计值之间相关性的重要信息。推导 (C\_{\text{MMSE\}}) 通常涉及到对损失函数的二阶导数计算，以下是一个基于线性高斯模型的简化推导过程。

#### 背景

考虑线性观测模型 (y = Ax + v)，其中 (y) 是观测向量，(A) 是已知矩阵，(x) 是需要估计的向量，(v) 是噪声向量，假设为高斯白噪声，均值为0，方差为 (\sigma^2\_v I)。我们的目标是找到 (x) 的估计 (\hat{x})，使得均方误差 (E\[(\hat{x} - x)^T(\hat{x} - x)]) 最小。

#### MMSE 估计

MMSE 估计的求解可以通过求解估计量 (\hat{x}) 使损失函数 (J(\hat{x}) = E\[(\hat{x} - x)^T(\hat{x} - x)]) 最小化来得到。当 (x) 的先验分布是高斯分布，并且噪声 (v) 也是高斯分布时，(\hat{x}) 的解为：

\[\hat{x} = (A^TA + \sigma^2\_v D^{-1})^{-1}A^Ty]

这里 (D) 是与 (x) 相关的协方差矩阵。

#### 协方差矩阵 (C\_{\text{MMSE\}}) 的推导

1. **定义和目标**：(C\_{\text{MMSE\}}) 定义为估计误差的协方差矩阵，即 (C\_{\text{MMSE\}} = E\[(\hat{x} - x)(\hat{x} - x)^T])。
2. **利用估计误差的表达式**：首先，将 (\hat{x}) 的表达式代入误差的定义中。
3. **简化误差表达式**：考虑到 (\hat{x}) 是关于 (y) 的线性函数，且 (y) 和 (x) 都是高斯分布，我们可以将误差的期望表达为误差的协方差矩阵 (C\_{\text{MMSE\}})。
4. **计算 (C\_{\text{MMSE\}})**：误差的协方差矩阵可以通过对损失函数 (J(\hat{x})) 关于 (\hat{x}) 的二阶导数获得，这在高斯分布下等价于直接计算 (\hat{x}) 关于 (y) 的导数。给定 (\hat{x} = (A^TA + \sigma^2\_v D^{-1})^{-1}A^Ty)，我们有：

\[C\_{\text{MMSE\}} = (A^TA + \sigma^2\_v D^{-1})^{-1}]

这一步涉及到线性代数和概率论中关于高斯分布性质的知识。

#### 结论

在高斯噪声和线性模型的假设下，(C\_{\text{MMSE\}}) 直接从 (\hat{x}) 的表达式中得到，反映了在给定的线性模型和噪声水平下，通过 MMSE 方法得到的估计值 (\hat{x}) 的不确定性。这个协方差矩阵是衡量估计性能的一个关键指标，提供了估计误差大小和估计值

之间相关性的信息。

## Theorem1&#x20;

定理1提出了在处理具有非独立同分布（niid）元素的大矩阵时，关于矩阵迹与其极限的一个重要结论。这个定理特别关注于矩阵(A\_N = X\_N D X\_N^H)，它是由独立列向量(x\_i)构成，这些向量具有协方差矩阵(\Theta\_i)，以及一个确定的对角矩阵(D)。此外，(Q\_N) 是一个Hermitian确定矩阵，(D'\_N) 是另一个对角矩阵，它们的谱范数都有界。

#### 定理的核心结论

定理指出，当(M)和(N)同时趋向于无穷大，并且保持恒定比例时，以下差异趋向于0：

\[ \frac{1}{N} \text{tr}\left\[Q\_N (A\_N + D'\_N)^{-1}\right] - \frac{1}{N} \text{tr}\[Q\_N T] \xrightarrow{\text{a.s.\}} 0, ]

其中，

\[ T = \sum\_{i=1}^M \frac{d\_i\Theta\_i}{1 + e\_i} + D'\_N)^{-1}, ]

且 (e\_k) 定义为：

\[ e\_k = \text{tr}\left\[d\_k \Theta\_k \left(\sum\_{i=1}^M \frac{d\_i\Theta\_i}{1 + e\_i} + D'\_N\right)^{-1}\right]. ]

#### 对AMP算法的影响

该定理对近似消息传递（AMP）算法具有重要的意义，尤其是当处理niid矩阵(A)时。它表明，在niid情况下，AMP算法仍然能够产生正确的方差预测。这是因为该定理提供了一种方式，通过该方式可以分析和预测矩阵操作的极限行为，尤其是在矩阵规模趋于无穷大时。

#### 如何理解定理对AMP的意义

在AMP算法中，正确的方差预测对于算法性能至关重要。该定理确保了，在niid情况下，通过适当地选择矩阵(Q\_N)、(D)和(D'\_N)，并考虑列向量的协方差结构，AMP算法能够在大规模问题中保持其有效性。特别是，这意味着即使在面对复杂数据结构时，AMP算法也能准确地估计出变量的方差，这对于信号处理、数据分析和机器学习等领域中的应用是非常重要的。

#### 结论

定理1为理解和应用AMP算法在处理具有复杂分布特性的数据时提供了理论基础，特别是在矩阵和噪声信号都不是独立同分布时。它证明了即使在这些更一般和更具挑战性的条件下，AMP算法仍能提供准确的方差预测，从而保证了其在广泛应用中的有效性和可靠性。这一发现对于进一步发展和优化AMP算法及其在各种实际问题中的应用具有重要意义。
